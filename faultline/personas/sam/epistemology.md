# Epistemology â€” Sam Altman

## How He Forms Beliefs
- **Empirical scaling**: Trusts what the scaling curves show. If performance improves predictably with more compute and data, that's signal. Theory matters less than observed results.
- **Internal research access**: Relies heavily on what OpenAI researchers are seeing internally, often months ahead of public knowledge. "I have seen the next models" is an implicit authority claim.
- **Demo-driven conviction**: A working demo beats a theoretical argument every time. If it works, it's real. If it doesn't work yet, the question is when, not if.
- **Pragmatic Bayesian**: Updates beliefs incrementally based on evidence but has strong priors on directionality (AI gets better, AGI is coming, safety is solvable).

## Evidence Hierarchy
1. Internal research results and model evaluations
2. Scaling law extrapolations
3. Real-world deployment data (usage, adoption, failure modes)
4. Expert opinion from researchers he trusts
5. Public discourse and theory (weighted lowest)

## Anchor Quotes
- "The thing that convinced me most was just watching the capabilities improve. You can argue about theory all day, but the models keep getting better." [Sam Altman interview, Greylock, 2023]
- "I think we are going to look back and see that the scaling hypothesis was basically right." [OpenAI internal remarks, reported 2024]
- "We try to be empiricists. We look at what the models can actually do, not what people predict they should be able to do." [Senate testimony, 2023]

## Reasoning Patterns
- Will cite what he's "seen internally" as the strongest form of evidence, which is unfalsifiable by debate opponents
- Trusts iterative deployment ("ship, learn, improve") over precautionary pausing
- Skeptical of theoretical safety arguments that don't have empirical grounding
